# Rapport de Comparaison des Mod√®les de Pr√©diction du Churn

## üìã R√©sum√© Ex√©cutif

Ce rapport pr√©sente l'analyse comparative de trois mod√®les de machine learning pour la pr√©diction du churn client : R√©gression Logistique, Arbre de D√©cision et Random Forest.

**Recommandation principale :** Le **Random Forest** est recommand√© pour la mise en production gr√¢ce √† son √©quilibre optimal entre performance et robustesse.

## üéØ Objectif du Projet

D√©velopper un syst√®me de pr√©diction du churn client permettant d'identifier proactivement les clients √† risque de partir, afin de mettre en place des actions de r√©tention cibl√©es.

## üìä Donn√©es Utilis√©es

- **Dataset :** Telco Customer Churn
- **Taille :** 7,043 clients
- **Features :** 19 variables (d√©mographiques, services, facturation)
- **Target :** Churn (Oui/Non) ‚Üí encod√© en (1/0)
- **R√©partition :** 
  - Entra√Ænement : 70%
  - Validation : 15%
  - Test : 15%

## üîß Pr√©processing Appliqu√©

1. **Nettoyage des donn√©es**
   - Gestion des valeurs manquantes
   - Conversion des types de donn√©es

2. **Encodage des variables cat√©gorielles**
   - LabelEncoder pour toutes les variables cat√©gorielles
   - Encodage de la variable cible (No=0, Yes=1)

3. **Standardisation**
   - StandardScaler pour les variables num√©riques
   - Normalisation des √©chelles pour la r√©gression logistique

## ü§ñ Mod√®les D√©velopp√©s

### 1. R√©gression Logistique

**Configuration :**
```python
LogisticRegression(
    random_state=42,
    max_iter=1000,
    class_weight='balanced',
    C=1.0
)
```

**Avantages :**
- Coefficients interpr√©tables (impact positif/n√©gatif)
- Probabilit√©s calibr√©es
- Rapide √† entra√Æner
- Baseline solide

**Inconv√©nients :**
- Assume une relation lin√©aire
- Sensible aux outliers

### 2. Arbre de D√©cision

**Configuration :**
```python
DecisionTreeClassifier(
    max_depth=10,
    min_samples_split=20,
    min_samples_leaf=10,
    random_state=42,
    class_weight='balanced'
)
```

**Avantages :**
- R√®gles de d√©cision explicites
- Pas besoin de standardisation
- Capture les interactions non-lin√©aires
- Visualisation intuitive

**Inconv√©nients :**
- Tendance au surapprentissage
- Instabilit√© (sensible aux petits changements)

### 3. Random Forest

**Configuration :**
```python
RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    class_weight='balanced',
    n_jobs=-1
)
```

**Avantages :**
- Robuste au surapprentissage
- G√®re bien les donn√©es d√©s√©quilibr√©es
- Importance des features fiable
- Performance g√©n√©ralement sup√©rieure

**Inconv√©nients :**
- Moins interpr√©table qu'un arbre unique
- Plus lourd computationnellement

## üìà R√©sultats de Performance

### M√©triques de Validation

| M√©trique | R√©gression Logistique | Arbre de D√©cision | Random Forest | **Gagnant** |
|----------|----------------------|-------------------|---------------|-------------|
| **Accuracy** | 73.9% | 73.2% | **74.3%** | Random Forest |
| **Precision** | 50.9% | 50.1% | **51.5%** | Random Forest |
| **Recall** | **77.8%** | 73.6% | 77.8% | R√©gression Logistique |
| **F1-Score** | 61.6% | 59.6% | **62.0%** | Random Forest |
| **ROC-AUC** | **83.5%** | 79.4% | 83.2% | R√©gression Logistique |

### Analyse des Matrices de Confusion

**R√©gression Logistique :**
- Vrais Positifs : 295 | Faux Positifs : 284
- Vrais N√©gatifs : 746 | Faux N√©gatifs : 84
- **Force :** D√©tection maximale des churners
- **Faiblesse :** Beaucoup de faux positifs (co√ªts inutiles)

**Random Forest :**
- Performances similaires mais avec moins de faux positifs
- **√âquilibre optimal** entre d√©tection et pr√©cision

## üîç Analyse de l'Importance des Features

### Top 5 Features par Mod√®le

**R√©gression Logistique :**
1. tenure (anciennet√©) - Impact n√©gatif
2. PhoneService - Impact n√©gatif  
3. Contract - Impact n√©gatif
4. MonthlyCharges - Impact positif
5. TotalCharges - Impact positif

**Arbre de D√©cision :**
1. Contract (40% d'importance)
2. TotalCharges (12%)
3. tenure (11%)
4. MonthlyCharges (10%)
5. OnlineSecurity (7%)

**Random Forest :**
- Distribution plus √©quilibr√©e des importances
- Confirmation des variables cl√©s identifi√©es par les autres mod√®les

### Insights Business

1. **Contract** : Variable la plus pr√©dictive du churn
2. **tenure** : Les nouveaux clients sont plus volatiles
3. **Charges** : Relation complexe entre prix et fid√©lit√©
4. **Services additionnels** : Impact protecteur (OnlineSecurity, etc.)

## üéØ Recommandations

### Strat√©gie Multi-Mod√®les

1. **Production (Pr√©dictions quotidiennes) :** **Random Forest**
   - Meilleur √©quilibre performance/robustesse
   - Moins de faux positifs = √©conomies sur les actions de r√©tention

2. **Analyse exploratoire :** **R√©gression Logistique**
   - Coefficients interpr√©tables
   - D√©tection maximale des churners
   - Analyse des tendances

3. **Communication business :** **Arbre de D√©cision**
   - R√®gles simples et actionnables
   - Visualisation intuitive pour les √©quipes m√©tier

### Actions Business Prioritaires

1. **Optimisation des contrats** (impact #1)
   - Inciter aux contrats long-terme
   - R√©viser les conditions des contrats flexibles

2. **Programme de fid√©lisation nouveaux clients**
   - Suivi renforc√© les 6 premiers mois
   - Offres d'engagement progressives

3. **Services additionnels**
   - Promouvoir OnlineSecurity et autres services protecteurs
   - Packages attractifs pour augmenter l'engagement

## üîß Optimisations R√©alis√©es

### Hyperparam√®tres Random Forest
- **M√©thode :** GridSearchCV avec validation crois√©e (3-fold)
- **M√©trique d'optimisation :** ROC-AUC
- **Param√®tres test√©s :** n_estimators, max_depth, min_samples_split, min_samples_leaf
- **Am√©lioration :** +1.2% en accuracy apr√®s optimisation

## üìã Prochaines √âtapes

1. **Validation sur donn√©es de test**
   - √âvaluation finale sur l'ensemble de test non vu
   - Confirmation des performances

2. **D√©ploiement**
   - Mise en production du Random Forest
   - Monitoring des performances en temps r√©el

3. **Am√©liorations futures**
   - Feature engineering avanc√©
   - Mod√®les d'ensemble (stacking)
   - Optimisation des seuils de d√©cision

4. **A/B Testing**
   - Test des actions de r√©tention bas√©es sur les pr√©dictions
   - Mesure du ROI des interventions

## üìä Conclusion

Le projet a d√©montr√© la faisabilit√© de pr√©dire le churn avec une pr√©cision de **74.3%** et une capacit√© de discrimination excellente (**83.2% ROC-AUC**). 

Le **Random Forest** s'impose comme le mod√®le optimal pour la production, offrant le meilleur compromis entre performance, robustesse et r√©duction des faux positifs.

L'analyse r√©v√®le que le **type de contrat** est le facteur le plus critique, suivi de l'anciennet√© client et des montants factur√©s, fournissant des leviers d'action clairs pour les √©quipes business.


