# ğŸ¯ Projet de PrÃ©diction du Churn Client

## ğŸ“‹ Description

Ce projet dÃ©veloppe un systÃ¨me de machine learning pour prÃ©dire le churn (dÃ©sabonnement) des clients d'une entreprise de tÃ©lÃ©communications. L'objectif est d'identifier proactivement les clients Ã  risque de partir afin de mettre en place des stratÃ©gies de rÃ©tention ciblÃ©es.

## ğŸ† RÃ©sultats Principaux

- **Meilleur modÃ¨le :** Random Forest (74.3% accuracy, 83.2% ROC-AUC)
- **Facteur #1 de churn :** Type de contrat (40% d'importance)
- **ROI estimÃ© :** RÃ©duction de 51.5% des actions de rÃ©tention inutiles

## ğŸ“Š Comparaison des ModÃ¨les

### RÃ©sultats DÃ©taillÃ©s
```
=== COMPARAISON COMPLÃˆTE DES MODÃˆLES ===
           RÃ©gression Logistique  Arbre de DÃ©cision  Random Forest
accuracy                   0.739              0.732          0.743
precision                  0.509              0.501          0.515
recall                     0.778              0.736          0.778
f1                         0.616              0.596          0.620
roc_auc                    0.835              0.794          0.832

=== MEILLEUR MODÃˆLE PAR MÃ‰TRIQUE ===
accuracy: Random Forest (0.743)
precision: Random Forest (0.515)
recall: RÃ©gression Logistique (0.778)
f1: Random Forest (0.620)
roc_auc: RÃ©gression Logistique (0.835)
```

### Usage RecommandÃ© par ModÃ¨le
| ModÃ¨le | Usage RecommandÃ© | Raison |
|--------|------------------|--------|
| **Random Forest** | **Production** | Meilleur Ã©quilibre gÃ©nÃ©ral |
| **RÃ©gression Logistique** | **Analyse** | Meilleur recall et ROC-AUC |
| **Arbre de DÃ©cision** | **Communication** | Plus interprÃ©table |

## ğŸ—ï¸ Structure du Projet

```
churn_prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # DonnÃ©es brutes (Telco Customer Churn)
â”‚   â””â”€â”€ processed/              # DonnÃ©es prÃ©traitÃ©es et divisÃ©es
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb     # Analyse exploratoire
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb   # PrÃ©traitement des donnÃ©es
â”‚   â””â”€â”€ 03_model_development.ipynb    # DÃ©veloppement et comparaison des modÃ¨les
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ dataset.py          # Gestion des donnÃ©es
â”‚   â”‚   â”œâ”€â”€ preprocessor.py     # Pipeline de prÃ©processing
â”‚   â”‚   â””â”€â”€ process_data.py     # Script de traitement des donnÃ©es
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ base_model.py       # Classe abstraite commune
â”‚       â”œâ”€â”€ logistic_regression.py  # ModÃ¨le de rÃ©gression logistique
â”‚       â”œâ”€â”€ decision_tree.py    # ModÃ¨le d'arbre de dÃ©cision
â”‚       â””â”€â”€ random_forest.py    # ModÃ¨le Random Forest (avec optimisation)
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ download_setup.py   # TÃ©lÃ©chargement et setup automatique
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ model_comparison_report.md  # Rapport dÃ©taillÃ© des rÃ©sultats
â”œâ”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s sauvegardÃ©s
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Installation et Utilisation

### 1. Setup Initial
```bash
git clone <repository-url>
cd churn_prediction
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 2. TÃ©lÃ©chargement Automatique des DonnÃ©es
```bash
python scripts/data/download_setup.py
```
*TÃ©lÃ©charge automatiquement le dataset Kaggle et applique le prÃ©processing*

### 3. Exploration et DÃ©veloppement
```bash
# Lancer Jupyter
jupyter notebook

# ExÃ©cuter dans l'ordre :
# 1. notebooks/01_data_exploration.ipynb
# 2. notebooks/02_data_preprocessing.ipynb  
# 3. notebooks/03_model_development.ipynb
```

### 4. Utilisation Rapide des ModÃ¨les
```python
# Import des modÃ¨les
from src.models.random_forest import RandomForestModel
from src.models.logistic_regression import LogisticRegressionModel

# Chargement des donnÃ©es
import pandas as pd
X_train = pd.read_csv('data/processed/X_train.csv')
y_train = pd.read_csv('data/processed/y_train.csv')['0']

# EntraÃ®nement Random Forest
rf_model = RandomForestModel()
rf_model.train(X_train, y_train)

# PrÃ©dictions
predictions = rf_model.predict(X_test)
probabilities = rf_model.predict_proba(X_test)
```

## ğŸ¯ FonctionnalitÃ©s ClÃ©s

### ModÃ¨les ImplÃ©mentÃ©s
- âœ… **RÃ©gression Logistique** avec analyse des coefficients
- âœ… **Arbre de DÃ©cision** avec visualisation des rÃ¨gles
- âœ… **Random Forest** avec optimisation automatique des hyperparamÃ¨tres

### Analyses AvancÃ©es
- ğŸ“Š **Matrices de confusion** interactives
- ğŸ“ˆ **Courbes ROC** comparatives  
- ğŸ¯ **Importance des features** par modÃ¨le
- ğŸŒ³ **Visualisation de l'arbre de dÃ©cision**
- âš™ï¸ **Optimisation automatique** des hyperparamÃ¨tres

### Pipeline Complet
- ğŸ”„ **PrÃ©processing automatisÃ©** (nettoyage, encodage, standardisation)
- ğŸ“Š **Ã‰valuation multi-mÃ©triques** (accuracy, precision, recall, F1, ROC-AUC)
- ğŸ’¾ **Sauvegarde des modÃ¨les** entraÃ®nÃ©s
- ğŸ“‹ **Rapports automatiques** de performance

## ğŸ“ˆ Insights Business

### Facteurs ClÃ©s de Churn
1. **Type de contrat** (40% d'importance) - Contrats flexibles = risque Ã©levÃ©
2. **AnciennetÃ© client** (11%) - Nouveaux clients plus volatiles  
3. **Montants facturÃ©s** (10%) - Relation complexe prix/fidÃ©litÃ©
4. **Services additionnels** - Impact protecteur (OnlineSecurity, etc.)

### Recommandations StratÃ©giques
- ğŸ¯ **PrioritÃ© #1** : Optimiser les types de contrats (inciter long-terme)
- ğŸ‘¥ **Nouveaux clients** : Suivi renforcÃ© les 6 premiers mois
- ğŸ“¦ **Services additionnels** : Promouvoir les packages protecteurs
- ğŸ’° **Pricing** : RÃ©viser la stratÃ©gie tarifaire selon l'anciennetÃ©

## ğŸ“Š MÃ©triques et Performance

### MÃ©triques d'Ã‰valuation
- **Accuracy** : Performance globale du modÃ¨le
- **Precision** : RÃ©duction des faux positifs (actions inutiles)
- **Recall** : DÃ©tection des vrais churners (ne pas les manquer)
- **F1-Score** : Ã‰quilibre precision/recall
- **ROC-AUC** : CapacitÃ© de discrimination

### Validation Robuste
- âœ… Division train/validation/test (70%/15%/15%)
- âœ… Validation croisÃ©e pour l'optimisation
- âœ… MÃ©triques sur donnÃ©es non vues
- âœ… Analyse des matrices de confusion

## ğŸ”§ Configuration Technique

### DÃ©pendances Principales
```
pandas>=1.3.0
numpy>=1.21.0
scikit-learn>=1.0.0
matplotlib>=3.4.0
seaborn>=0.11.0
jupyter>=1.0.0
kaggle>=1.5.0
```

### Optimisations ImplÃ©mentÃ©es
- ğŸš€ **ParallÃ©lisation** (n_jobs=-1) pour Random Forest
- âš–ï¸ **Gestion du dÃ©sÃ©quilibre** (class_weight='balanced')
- ğŸ›ï¸ **GridSearchCV** pour l'optimisation automatique
- ğŸ’¾ **Sauvegarde/chargement** des modÃ¨les avec joblib

## ğŸ“š Documentation

- ğŸ“‹ **Rapport complet** : `docs/model_comparison_report.md`
- ğŸ““ **Notebooks dÃ©taillÃ©s** avec analyses pas-Ã -pas
- ğŸ’¡ **Code commentÃ©** et docstrings complÃ¨tes
- ğŸ¯ **Exemples d'utilisation** dans chaque module

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/NouvelleFonctionnalite`)
3. Commit les changements (`git commit -m 'Ajout NouvelleFonctionnalite'`)
4. Push vers la branche (`git push origin feature/NouvelleFonctionnalite`)
5. Ouvrir une Pull Request


*ğŸ¯ Projet dÃ©veloppÃ© pour la prÃ©diction proactive du churn client*  
*ğŸ“Š RÃ©sultats : 74.3% accuracy avec Random Forest optimisÃ©*